// libsyntax implements a tokenier and parser for the Oak language

{
	println: println
	slice: slice
	append: append
	contains?: contains?
	map: map
	each: each
	filter: filter
	reduce: reduce
} := import('std')

{
	digit?: digit?
	word?: word?
	space?: space?
	contains?: strContains?
	trim: trim
} := import('str')

{
	format: format
} := import('fmt')

fn renderPos(pos) '[' + string(pos.0) + ':' + string(pos.1) + ']'

fn renderToken(token) if token.val {
	? -> format('{{ 0 }} {{ 1 }}', string(token.type), renderPos(token.pos))
	_ -> format('{{ 0 }}({{ 1 }}) {{ 2 }}', string(token.type), token.val, renderPos(token.pos))
}

// Tokenizer is a full-fidelity, lossless tokenizer for Oak. It produces a
// stream of valid Oak token types, plus any shebang, newlines, and comments it
// finds. To produce an AST, those non-standard non-AST tokens should be
// filtered out of the list first.
//
// Methods:
//
// fn tokenize()    returns a list of tokens
fn Tokenizer(source) {
	index := 0
	line := 1
	col := 0

	fn TokenAt(type, pos, val) {
		type: type
		val: val
		pos: pos
	}

	fn Token(type, val) TokenAt(type, [line, col], val)

	fn pos [line, col]
	fn eof? index = len(source)
	fn peek source.(index)
	fn peekAhead(n) if index + n > len(source) {
		true -> ' '
		_ -> source.(index + n)
	}
	fn next {
		char := source.(index)
		if index < len(source) {
			true -> index <- index + 1
		}
		if char {
			'\n' -> {
				line <- line + 1
				col <- 0
			}
			_ -> col <- col + 1
		}
		char
	}
	fn back {
		if index > 0 {
			true -> index <- index - 1
		}
		if source.(index) {
			// TODO: reset col correctly on backtrack
			'\n' -> line <- line - 1
			_ -> col <- col - 1
		}
	}

	fn readUntilChar(c) {
		fn sub(acc) if !eof?() & peek() != c {
			true -> sub(acc << next())
			_ -> acc
		}
		sub('')
	}
	fn readValidIdentifier {
		fn sub(acc) if eof?() {
			true -> acc
			_ -> {
				c := next()
				if word?(c) | c = '_' | c = '?' | c = '!' {
					true -> sub(acc << c)
					_ -> {
						back()
						acc
					}
				}
			}
		}
		sub('')
	}
	fn readValidNumeral {
		fn sub(acc) if eof?() {
			true -> acc
			_ -> {
				c := next()
				if digit?(c) | c = '.' {
					true -> sub(acc << c)
					_ -> {
						back()
						acc
					}
				}
			}
		}
		sub('')
	}
	fn nextToken if c := next() {
		',' -> Token(:comma)
		'.' -> if peek() = '.' & peekAhead(1) = '.' {
			true -> {
				pos := [line, col]
				next()
				next()
				TokenAt(:ellipsis, pos)
			}
			_ -> Token(:dot)
		}
		'(' -> Token(:leftParen)
		')' -> Token(:rightParen)
		'[' -> Token(:leftBracket)
		']' -> Token(:rightBracket)
		'{' -> Token(:leftBrace)
		'}' -> Token(:rightBrace)
		':' -> if peek() {
			'=' -> {
				pos := [line, col]
				next()
				TokenAt(:assign, pos)
			}
			_ -> Token(:colon)
		}
		'<' -> if peek() {
			'<' -> {
				pos := [line, col]
				next()
				TokenAt(:pushArrow, pos)
			}
			'-' -> {
				pos := [line, col]
				next()
				TokenAt(:nonlocalAssign, pos)
			}
			'=' -> {
				pos := [line, col]
				next()
				TokenAt(:leq, pos)
			}
			_ -> Token(:less)
		}
		'?' -> Token(:qmark)
		'!' -> if peek() {
			'=' -> {
				pos := [line, col]
				next()
				TokenAt(:neq, pos)
			}
			_ -> Token(:exclam)
		}
		'+' -> Token(:plus)
		'-' -> if peek() {
			'>' -> {
				pos := [line, col]
				next()
				TokenAt(:branchArrow, pos)
			}
			_ -> Token(:minus)
		}
		'*' -> Token(:times)
		'/' -> if peek() {
			'/' -> {
				// line comment
				pos := [line, col]
				next()
				commentString := readUntilChar('\n') |> trim()
				TokenAt(:comment, pos, commentString)
			}
			_ -> Token(:divide)
		}
		'%' -> Token(:modulus)
		'^' -> Token(:xor)
		'&' -> Token(:and)
		'|' -> if peek() {
			'>' -> {
				pos := [line, col]
				next()
				TokenAt(:pipeArrow, pos)
			}
			_ -> Token(:or)
		}
		'>' -> if peek() {
			'=' -> {
				pos := [line, col]
				next()
				TokenAt(:geq, pos)
			}
			_ -> Token(:greater)
		}
		'=' -> Token(:eq)
		'\'' -> {
			// TODO: support literal newlines, with extra tabs collapsed to newlines
			// TODO: support unicode escape sequences, like '\x10' = '\n' = char(10)
			fn sub(payload) if charInString := next() {
				? -> payload
				'\'' -> payload
				'\\' -> {
					if charInString := next() {
						'n' -> charInString := '\n'
						'r' -> charInString := '\r'
						'f' -> charInString := '\f'
						't' -> charInString := '\t'
					}
					sub(payload << charInString)
				}
				_ -> sub(payload << charInString)
			}
			pos := [line, col]
			stringContent := sub('')
			TokenAt(:stringLiteral, pos, stringContent)
		}
		_ -> {
			pos := [line, col]
			if digit?(c) {
				true -> {
					numberContent := c << readValidNumeral()
					TokenAt(:numberLiteral, pos, numberContent)
				}
				_ -> if payload := c << readValidIdentifier() {
					'_' -> TokenAt(:underscore, pos)
					'if' -> TokenAt(:ifKeyword, pos)
					'fn' -> TokenAt(:fnKeyword, pos)
					'with' -> TokenAt(:withKeyword, pos)
					'true' -> TokenAt(:trueLiteral, pos)
					'false' -> TokenAt(:falseLiteral, pos)
					_ -> TokenAt(:identifier, pos, payload)
				}
			}
		}
	}
	fn tokenize {
		tokens := []

		if peek() = '#' & peekAhead(1) = '!' {
			true -> {
				readUntilChar('\n')
				if !eof?() {
					true -> next()
				}
			}
		}

		// snip whitespace before
		fn eatSpace if space?(sp := peek()){
			true -> {
				if sp {
					'\n' -> tokens << Token(:newline)
				}
				next()
				eatSpace()
			}
		}
		eatSpace()

		lastTok := Token(:comma)
		fn sub {
			nextTok := nextToken()

			if !([:leftParen, :leftBracket, :leftBrace, :comma] |> contains?(lastTok.type)) &
				[:rightParen, :rightBracket, :rightBrace] |> contains?(nextTok.type) {
				true -> tokens << Token(:comma)
			}

			tokens << nextTok
			if nextTok.type {
				:comment -> nextTok := lastTok
			}

			// snip whitespace after
			fn eatSpaceAutoInsertComma if space?(peek()){
				true -> {
					if peek() {
						'\n' -> {
							if [
								:comma, :leftParen, :leftBracket, :leftBrace,
								:plus, :minus, :times, :divide, :modulus, :xor,
								:and, :or, :exclam, :greater, :less, :eq, :geq,
								:leq, :assign, :nonlocalAssign, :dot, :colon,
								:fnKeyword, :ifKeyword, :withKeyword,
								:pipeArrow, :branchArrow,
							] |> contains?(nextTok.type) {
								true -> ? // do nothing
								_ -> {
									nextTok <- Token(:comma)
									tokens << nextTok
								}
							}
							tokens << Token(:newline)
						}
					}
					next()
					eatSpaceAutoInsertComma()
				}
			}
			eatSpaceAutoInsertComma()

			if nextTok.type {
				:comment -> ?
				_ -> lastTok <- nextTok
			}

			if eof?() {
				false -> sub()
			}
		}

		// do not start tokenizing into empty file
		if eof?() {
			false -> sub()
		}

		if lastTok.type {
			:comma -> ?
			_ -> tokens << Token(:comma)
		}

		tokens
	}

	{
		tokenize: tokenize
	}
}

// Parser takes a raw token stream, potentially including newlines and
// comments, and generates a list of clean Oak AST nodes.
//
// Methods:
//
// fn parse()   returns a list of AST nodes
fn Parser(tokens) {
	index := 0
	minBinaryPrec := [0]

	// for parsing purposes, we must ignore non-semantic tokens
	tokens := tokens |> filter(fn(tok) if tok.type {
		:newline, :comment -> false
		_ -> true
	})

	fn error(msg, pos) {
		type: :error
		error: msg
		pos: pos
	}

	fn lastMinPrec minBinaryPrec.(len(minBinaryPrec) - 1)
	fn pushMinPrec(prec) minBinaryPrec << prec
	fn popMinPrec minBinaryPrec <- slice(minBinaryPrec, 0, len(minBinaryPrec) - 1)
	fn eof? index = len(tokens)
	fn peek tokens.(index)
	fn peekAhead(n) if index + n > len(tokens) {
		true -> { type: :comma }
		_ -> tokens.(index + n)
	}
	fn next {
		tok := tokens.(index)
		if index < len(tokens) {
			true -> index <- index + 1
		}
		tok
	}
	fn back if index > 0 {
		true -> index <- index - 1
	}
	fn expect(type) if eof?() {
		true -> error(format('Unexpected end of input, expected {{0}}', type))
		_ -> {
			next := next()
			if next.type {
				type -> next
				_ -> error(format('Unexpected token {{0}}, expected {{1}}', next, type), next.pos)
			}
		}
	}
	fn readUntilTokenType(type) {
		tokens := []
		fn sub if !eof() & peek().type != type {
			true -> {
				tokens << next()
				sub()
			}
			_ -> tokens
		}
		sub()
	}

	fn notError(x, withNotErr) if x {
		{ type: :error, error: _, pos: _ } -> x
		_ -> withNotErr(x)
	}

	fn parseAssignment(left) if peek().type {
		:assign, :nonlocalAssign -> {
			nxt := next()
			node := {
				type: :assignment
				tok: nxt
				local?: nxt.type = :assign
				left: left
			}

			with notError(right := parseNode()) fn {
				node.right := right
				node
			}
		}
		_ -> left
	}

	// parseUnit is responsible for parsing the smallest complete syntactic
	// "units" of Oak's syntax, like literals including function literals,
	// grouped expressions in blocks, and if/with expressions.
	fn parseUnit {
		tok := next()
		if tok.type {
			:qmark -> { type: :null, tok: tok }
			:stringLiteral -> {
				type: :string
				tok: tok
				val: tok.val
			}
			:numberLiteral -> if tok.val |> strContains?('.') {
				true -> if parsed := float(tok.val) {
					? -> error(format('Could not parse floating point number {{0}}', tok.val), tok.pos)
					_ -> {
						type: :number
						tok: tok
						int?: false
						val: parsed
					}
				}
				_ -> if parsed := int(tok.val) {
					? -> error(format('Could not parse integer number {{0}}', tok.val), tok.pos)
					_ -> {
						type: :number
						tok: tok
						int?: true
						val: parsed
					}
				}
			}
			:trueLiteral -> {
				type: :boolean
				tok: tok
				val: true
			}
			:falseLiteral -> {
				type: :boolean
				tok: tok
				val: false
			}
			:colon -> if peek().type {
				:identifier -> {
					type: :atom
					tok: tok
					val: next().val
				}
				_ -> error(format('Expected identifier after ":", got {{0}}', peek()), peek().pos)
			}
			:leftBracket -> {
				pushMinPrec(0)

				itemNodes := []
				fn sub if !eof?() & peek().type != :rightBracket {
					true -> with notError(node := parseNode()) fn {
						with notError(err := expect(:comma)) fn {
							itemNodes << node
							sub()
						}
					}
				}
				with notError(sub()) fn {
					with notError(err := expect(:rightBracket)) fn {
						popMinPrec()

						{
							type: :list
							tok: tok
							elems: itemNodes
						}
					}
				}
			}
			:leftBrace -> {
				pushMinPrec(0)

				// empty {} is always considered an object -- an empty block is illegal
				if peek().type {
					:rightBrace -> {
						next() // eat the rightBrace
						popMinPrec()

						{
							type: :object
							tok: tok
							entries: []
						}
					}
					_ -> with notError(firstExpr := parseNode()) fn if eof?() {
						true -> error('Unexpected end of input inside block or object', tok.pos)
						_ -> if peek().type {
							:colon -> {
								// it's an object
								next() // eat the colon
								with notError(valExpr := parseNode()) fn {
									with notError(expect(:comma)) fn {
										entries := [{ key: firstExpr, val: valExpr }]

										fn sub if eof?() {
											false -> if peek().type {
												:rightBrace -> ?
												_ -> with notError(key := parseNode()) fn {
													with notError(expect(:colon)) fn {
														with notError(val := parseNode()) fn {
															with notError(expect(:comma)) fn {
																entries << { key: key, val: val }
																sub()
															}
														}
													}
												}
											}
										}
										with notError(sub()) fn {
											with notError(expect(:rightBrace)) fn {
												popMinPrec()

												{
													type: :object
													tok: tok
													entries: entries
												}
											}
										}
									}
								}
							}
							_ -> with notError(expect(:comma)) fn {
								// it's a block
								exprs := [firstExpr]

								fn sub if !eof?() & peek().type != :rightBrace {
									true -> with notError(expr := parseNode()) fn {
										with notError(expect(:comma)) fn {
											exprs << expr
											sub()
										}
									}
								}
								with notError(sub()) fn {
									with notError(expect(:rightBrace)) fn {
										popMinPrec()

										{
											type: :block
											tok: tok
											exprs: exprs
										}
									}
								}
							}
						}
					}
				}
			}
			:fnKeyword -> {
				pushMinPrec(0)

				name := if peek().type {
					// optional named fn
					:identifier -> next().val
					_ -> ''
				}

				args := []
				restArg := ''

				fn parseBody with notError(body := parseNode()) fn {
					// Exception to the "{} is empty object" rule is that `fn
					// {}` parses as a function with an empty block as a body.
					if body {
						{ type: :object, tok: _, entries: [] } -> body <- {
							type: :block
							tok: body.tok
							exprs: []
						}
					}
					popMinPrec()

					{
						type: :function
						name: name
						tok: tok
						args: args
						restArg: restArg
						body: body
					}
				}

				if peek().type {
					:leftParen -> {
						// optional argument list
						next() // eat the leftParen

						fn sub if eof?() {
							false -> if peek().type {
								:rightParen -> ?
								_ -> {
									arg := expect(:identifier)
									if arg.type {
										:error -> {
											back() // try again

											with notError(expect(:underscore)) fn {
												args << ''
												with notError(:comma) fn {
													sub()
												}
											}
										}
										_ -> if peek().type {
											:ellipsis -> {
												restArg <- arg.val
												next() // eat the ellipsis
												with notError(expect(:comma)) fn {
													sub()
												}
											}
											_ -> {
												args << arg.val
												with notError(expect(:comma)) fn {
													sub()
												}
											}
										}
									}
								}
							}
						}
						with notError(sub()) fn {
							with notError(expect(:rightParen)) fn {
								parseBody()
							}
						}
					}
					_ -> parseBody()
				}
			}
			:underscore -> {
				type: :empty
				tok: tok
			}
			:identifier -> {
				type: :identifier
				tok: tok
				val: tok.val
			}
			:minus, :exclam -> with notError(right := parseSubNode()) fn {
				type: :unary
				tok: :tok
				op: tok.type
				right: right
			}
			:ifKeyword -> {
				// We want to support multi-target branches, but don't want to
				// incur the performance overhead in the interpreter/evaluator
				// of keeping every single target as a Go slice, when the vast
				// majority of targets will be single-value, which requires
				// just a pointer to an astNode.
				//
				// So instead of doing that, we penalize the multi-value case
				// by essentially considering it syntax sugar and splitting
				// such branches into multiple AST branches, each with one
				// target value.
				pushMinPrec(0)
				with notError(condNode := parseNode()) fn {
					with notError(expect(:leftBrace)) fn {
						fn subBranch(branches) if eof?() {
							false -> if peek().type {
								:rightBrace -> branches
								_ -> {
									fn subTarget(targets) if eof?() {
										true -> targets
										_ -> with notError(target := parseNode()) fn if peek().type {
											:branchArrow -> targets << target
											_ -> with notError(expect(:comma)) fn {
												subTarget(targets << target)
											}
										}
									}
									with notError(targets := subTarget([])) fn {
										with notError(expect(:branchArrow)) fn {
											with notError(body := parseNode()) fn {
												with notError(expect(:comma)) fn {
													 subBranch(branches << targets |> map(fn(target) {
														type: :ifBranch
														target: target
														body: body
													}))
												}
											}
										}
									}
								}
							}
							_ -> branches
						}
						with notError(branches := subBranch([])) fn {
							with notError(expect(:rightBrace)) fn {
								popMinPrec()

								{
									type: :ifExpr
									tok: tok
									cond: condNode
									branches: branches
								}
							}
						}
					}
				}
			}
			:withKeyword -> {
				pushMinPrec(0)
				with notError(base := parseNode()) fn if base.type {
					:fnCall -> with notError(lastArg := parseNode()) fn {
						popMinPrec()
						base.args << lastArg
						base
					}
					_ -> error(format('with keyword should be followed by a fn call, found {{0}}', base), tok.pos)
				}
			}
			:leftParen -> {
				pushMinPrec(0)

				fn subExpr(exprs) if !eof?() & peek().type != :rightParen {
					true -> with notError(expr := parseNode()) fn {
						with notError(expect(:comma)) fn {
							subExpr(exprs << expr)
						}
					}
					_ -> exprs
				}
				with notError(exprs := subExpr([])) fn {
					with notError(expect(:rightParen)) fn {
						popMinPrec()
						{
							type: :block
							tok: tok
							exprs: exprs
						}
					}
				}
			}
			_ -> error(format('Unexpected token {{0}} at start of unit', tok), tok.pos)
		}
	}

	fn infixOpPrecedence(op) if op {
		:plus, :minus -> 40
		:times, :divide -> 50
		:modulus -> 80
		:eq, :greater, :less, :geq, :leq, :neq -> 30
		:and -> 20
		:xor -> 15
		:or -> 10
		// assignment-like semantics
		:pushArrow -> 1
		_ -> -1
	}

	// parseSubNode is responsible for parsing independent "terms" in the Oak
	// syntax, like terms in unary and binary expressions and in pipelines. It
	// is in between parseUnit and parseNode.
	fn parseSubNode {
		pushMinPrec(0)
		with notError(node := parseUnit()) fn {
			fn sub if eof?() {
				false -> if peek().type {
					:dot -> {
						nxt := next() // eat the dot
						with notError(right := parseUnit()) fn {
							node <- {
								type: :propertyAccess
								tok: nxt
								left: node
								right: right
							}
							sub()
						}
					}
					:leftParen -> {
						nxt := next() // eat the leftParen

						args := []
						restArg := ?
						fn subArg if eof?() {
							false -> if peek().type {
								:rightParen -> with notError(expect(:rightParen)) fn {
									?
								}
								_ -> with notError(arg := parseNode()) fn if peek().type {
									:ellipsis -> {
										next() // eat the ellipsis
										with notError(expect(:comma)) fn {
											restArg <- arg
											subArg()
										}
									}
									:comma -> {
										next() // eat the comma
										args << arg
										subArg()
									}
									_ -> error(format('Expected comma after arg in argument list, got {{0}}', peek().type), peek().pos)
								}
							}
						}
						with notError(subArg()) fn {
							node <- {
								type: :fnCall
								function: node
								args: args
								restArg: restArg
								tok: nxt
							}
							sub()
						}
					}
				}
			}
			with notError(sub()) fn {
				popMinPrec()
				node
			}
		}
	}

	// parseNode returns the next top-level astNode from the parser
	fn parseNode with notError(node := parseSubNode()) fn {
		fn sub if eof?() {
			false -> if peek().type {
				:comma -> ?
				// whatever follows an assignment expr cannot bind to the
				// assignment expression itself by syntax rule, so we simply
				// return
				:assign, :nonlocalAssign -> node <- parseAssignment(node)
				// this case implements a mini Pratt parser threaded through
				// the larger Oak syntax parser, using the parser struct itself
				// to keep track of the power / precedence stack since other
				// forms may be parsed in between, as in 1 + f(g(x := y)) + 2
				:plus, :minus, :times, :divide, :modulus, :xor, :and, :or,
				:pushArrow, :greater, :less, :eq, :geq, :leq, :neq -> {
					minPrec := lastMinPrec()
					fn subBinary if eof?() {
						true -> error('Incomplete binary expression', peek().pos)
						_ -> {
							peeked := peek()
							op := peeked.type
							prec := infixOpPrecedence(op)
							if prec <= minPrec {
								false -> {
									next() // eat the operator

									if eof?() {
										true -> error(format('Incomplete binary expression with {{0}}', {type: op}), peek().pos)
										_ -> {
											pushMinPrec(prec)
											with notError(right := parseNode()) fn {
												popMinPrec()

												node <- {
													type: :binary
													tok: peeked
													op: op
													left: node
													right: right
												}
												subBinary()
											}
										}
									}
								}
							}
						}
					}
					with notError(subBinary()) fn {
						// whatever follows a binary expr cannot bind to the
						// binary expression by syntax rule, so we simply
						// return
						node
					}
				}
				:pipeArrow -> {
					pipe := next() // eat the pipe
					with notError(pipeRight := parseSubNode()) fn if pipeRight.type {
						:fnCall -> {
							pipeRight.args := append([node], pipeRight.args)
							node <- pipeRight
							sub()
						}
						_ -> error(format('Expected function call after |>, got {{0}}', pipeRight), pipe.pos)
					}
				}
			}
		}
		// the trailing comma is handled as necessary in callers of parseNode
		with notError(sub()) fn {
			node
		}
	}

	{
		parse: fn {
			// parse
			nodes := []
			fn sub if eof?() {
				false -> with notError(node := parseNode()) fn {
					with notError(expect(:comma)) fn {
						nodes << node
						sub()
					}
				}
			}
			with notError(sub()) fn {
				nodes
			}
		}
	}
}

