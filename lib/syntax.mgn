// library for working with Mangolia token streams and syntax trees

{
	println: println
	slice: slice
	contains?: contains?
	map: map
	each: each
	filter: filter
	reduce: reduce
} := import('std')

{
	digit?: digit?
	word?: word?
	space?: space?
	trim: trim
} := import('str')

{
	format: format
} := import('fmt')

fn renderPos(pos) '[' + string(pos.0) + ':' + string(pos.1) + ']'

fn renderToken(token) if token.val {
	? -> format('{{ 0 }} {{ 1 }}', string(token.type), renderPos(token.pos))
	_ -> format('{{ 0 }}({{ 1 }}) {{ 2 }}', string(token.type), token.val, renderPos(token.pos))
}

fn Tokenizer(source) {
	index := 0
	line := 0
	col := 0

	fn Token(type, val) {
		type: type
		val: val
		pos: [line, col]
	}

	fn pos [line, col]
	fn eof? index = len(source)
	fn peek source.(index)
	fn peekAhead(n) if index + n > len(source) {
		true -> ' '
		_ -> source.(index + n)
	}
	fn next {
		char := source.(index)
		if index < len(source) {
			true -> index <- index + 1
		}
		char
	}
	fn back if index > 0 {
		true -> index <- index - 1
	}

	fn readUntilChar(c) {
		fn sub(acc) if !eof?() & peek() != c {
			true -> sub(acc << next())
		}
		sub('')
	}
	fn readValidIdentifier {
		fn sub(acc) if eof?() {
			true -> acc
			_ -> {
				c := next()
				if word?(c) | c = '.' {
					true -> sub(acc << c)
					_ -> {
						back()
						acc
					}
				}
			}
		}
		sub('')
	}
	fn readValidNumeral {
		fn sub(acc) if eof?() {
			true -> acc
			_ -> {
				c := next()
				if digit?(c) | c = '.' {
					true -> sub(acc << c)
					_ -> {
						back()
						acc
					}
				}
			}
		}
		sub('')
	}
	fn nextToken if c := next() {
		',' -> Token(:comma)
		'.' -> if peek() = '.' & peekAhead(1) = '.' {
			true -> {
				next()
				next()
				Token(:ellipsis)
			}
			_ -> Token(:dot)
		}
		'(' -> Token(:leftParen)
		')' -> Token(:rightParen)
		'[' -> Token(:leftBracket)
		']' -> Token(:rightBracket)
		'{' -> Token(:leftBrace)
		'}' -> Token(:rightBrace)
		':' -> if peek() {
			'=' -> {
				next()
				Token(:assign)
			}
			_ -> Token(:colon)
		}
		'<' -> if peek() {
			'<' -> {
				next()
				Token(:pushArrow)
			}
			'-' -> {
				next()
				Token(:nonlocalAssign)
			}
			'=' -> {
				next()
				Token(:leq)
			}
			_ -> Token(:less)
		}
		'?' -> Token(:qmark)
		'!' -> if peek() {
			'=' -> {
				next()
				Token(:neq)
			}
			_ -> Token(:exclam)
		}
		'+' -> Token(:plus)
		'-' -> if peek() {
			'>' -> {
				next()
				Token(:branchArrow)
			}
			_ -> Token(:minus)
		}
		'*' -> Token(:times)
		'/' -> if peek() {
			'/' -> {
				// line comment
				next()
				commentString := readUntilChar('\n') |> trim()
				Token(:comment, commentString)
			}
			_ -> Token(:divide)
		}
		'%' -> Token(:modulus)
		'^' -> Token(:xor)
		'&' -> Token(:and)
		'|' -> if peek() {
			'>' -> {
				next()
				Token(:pipeArrow)
			}
			_ -> Token(:or)
		}
		'>' -> if peek() {
			'=' -> {
				next()
				Token(:geq)
			}
			_ -> Token(:greater)
		}
		'=' -> Token(:eq)
		'\'' -> {
			// TODO: support literal newlines, nextra tabs collapsed to newlines
			// TODO: support unicode escape sequences, like '\x10' = '\n' = char(10)
			fn sub(payload) if charInString := peek() {
				? -> payload
				'\'' -> {
					next() // eat the quote
					payload
				}
				'\\' -> {
					if charInString := next() {
						'n' -> charInString := '\n'
						'r' -> charInString := '\r'
						'f' -> charInString := '\f'
						't' -> charInString := '\t'
					}
					sub(payload << charInString)
				}
				_ -> sub(payload << charInString)
			}
			stringContent := sub('')
			Token(:stringLiteral, stringContent)
		}
		_ -> if digit?(c) {
			true -> {
				numberContent := c << readValidNumeral()
				Token(:numberLiteral, numberContent)
			}
			_ -> if payload := c << readValidIdentifier() {
				'_' -> Token(:underscore)
				'if' -> Token(:ifKeyword)
				'fn' -> Token(:fnKeyword)
				'with' -> Token(:withKeyword)
				'true' -> Token(:trueLiteral)
				'false' -> Token(:falseLiteral)
				_ -> Token(:identifier, payload)
			}
		}
	}
	fn tokenize {
		tokens := []

		if peek() = '#' & peekAhead(1) = '!' {
			true -> readUntilChar('\n')
			_ -> if !eof?() {
				true -> next()
			}
		}

		// snip whitespace before
		fn eatSpace if space?(peek()){
			true -> next()
		}
		eatSpace()

		lastTok := Token(:comma)
		fn sub {
			nextTok := nextToken()

			if [:leftParen, :leftBracket, :leftBrace, :comma] |> contains?(lastTok.type) &
				[:rightParen, :rightBracket, :rightBrace] |> contains?(nextTok.type) {
				true -> tokens << Token(:comma)
			}

			if nextTok.type {
				:comment -> nextTok := lastTok
				_ -> tokens << nextTok
			}

			// snip whitespace after
			fn eatSpaceAutoInsertComma if space?(peek()){
				true -> if peek() {
					'\n' -> if [
						:comma, :leftParen, :leftBracket, :leftBrace, :plus,
						:minus, :times, :divide, :modulus, :xor, :and, :or,
						:exclam, :greater, :less, :eq, :geq, :leq, :assign,
						:nonlocalAssign, :dot, :colon, :fnKeyword, :ifKeyword,
						:withKeyword, :pipeArrow, :branchArrow,
					] |> contains?(nextTok.type) {
						true -> ? // do nothing
						_ -> {
							nextTok <- Token(:comma)
							tokens << nextTok
						}
					}
					_ -> next()
				}
			}
			eatSpaceAutoInsertComma()

			if nextTok.type {
				:comment -> ?
				_ -> lastTok <- nextTok
			}

			if eof?() {
				true -> ?
				_ -> sub()
			}
		}
		sub()

		if lastTok.type {
			:comma -> ?
			_ -> tokens << Token(:comma)
		}

		tokens
	}

	{
		tokenize: tokenize
	}
}

// TODO: finish & test tokenizer, including in standard test suite, and then
// build 'mgn fmt' on top of this
// TODO: propagate token position information thru to end here
// tokenizer := Tokenizer('fn(ay) bee + sea')
// tokens := tokenizer.tokenize()
// tokens |> map(renderToken) |> each(fn(t) println(t))

